{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've learned how to build a linear regression model and interpret the estimated coefficients. In this checkpoint, we discuss how we evaluate model performance in the training phase. Recall that there are two contexts where we care about performance: in relation to the training set and in relation to a test set. The former enables us to talk about how well our model explains the information in the target variable, while the latter tells us how well our model will perform when it's given previously unseen observations.\n",
    "\n",
    "In this checkpoint we'll go over concepts like **F-test** and **R-squared**. F-test allow us to compare our model to a reduced model with no features. R-squared and **adjusted R-squared** (which is a variant of R-squared) values tell us how well the model accounts for variance in the target.\n",
    "\n",
    "Last, we explain how we can compare different models in terms of their explanatory power. We show how to read **Akaike** and **Bayesian** information criterias for this purpose.\n",
    "\n",
    "Main topics and key terms we'll cover in this checkpoint are:\n",
    "\n",
    "* train and test data\n",
    "* evaluating training performance\n",
    "* F-test\n",
    "* degrees of freedom\n",
    "* R-squared\n",
    "* Akaike Information Criterion\n",
    "* Bayesian Information Criterion\n",
    "\n",
    "At the end of this checkpoint, you'll work through two assignments where you'll evaluate the performance of your weather and house prices models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is our model better than an \"empty\" model?\n",
    "\n",
    "When evaluating our model, we first need to ask whether our model contributes anything to the explanation of the outcome variable. In other words, we need to determine whether or not our features explain variance in the outcome. If not, we could drop our features altogether and the resulting \"empty\" model would perform equally well (which is to say, not very well!).\n",
    "\n",
    "For this purpose, we use **F-test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The F-test\n",
    "\n",
    "The F-test can be calculated in different ways depending on the situation, but principally represents the ratio between the unexplained variance of our model and the unexplained variance of a reduced model to which our model is compared.  Here, the \"reduced model\" is a model with no features, meaning all variance in the outcome is unexplained.  For a linear regression model with two parameters $y=\\alpha+\\beta x$, the F-test is built from these pieces:\n",
    "\n",
    "* unexplained model variance:\n",
    "\n",
    "$$SSE_F=\\sum(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "* unexplained variance in reduced model:\n",
    "\n",
    "$$SSE_R=Var_y = \\sum(y_i-\\bar{y})^2$$\n",
    "\n",
    " * number of parameters in the model:\n",
    "\n",
    "$$p_F = 2 (\\alpha \\text{ and } \\beta)$$\n",
    "\n",
    " * number of parameters in the reduced model:\n",
    "\n",
    "$$p_R = 1 (\\alpha)$$\n",
    "\n",
    " * number of observations:\n",
    "\n",
    "$$n$$\n",
    "\n",
    " * degrees of freedom of $SSE_F$:\n",
    "\n",
    "$$df_F = n - p_F$$\n",
    "\n",
    " * degrees of freedom of $SSE_R$:\n",
    "\n",
    "$$df_R = n - p_R$$\n",
    "\n",
    "These pieces come together to give us the full equation for the F-test:\n",
    "\n",
    "$$F=\\dfrac{SSE_F-SSE_R}{df_F-df_R}÷\\dfrac{SSE_F}{df_F}$$\n",
    "\n",
    "This introduces some new terminology. **Degrees of freedom** quantify the amount of information \"left over\" to estimate variability after all parameters are estimated.\n",
    "\n",
    "In regression, degrees of freedom for a function works like this:  With two datapoints, a regression line $y=\\alpha + \\beta x$ has 0 degrees of freedom (2 minus the number of parameters).  Those two parameters encompass all the information in the data.  Knowing $\\alpha$ and $\\beta$ alone, we can perfectly reproduce the original data.  No additional information is available from the data itself. If we have 10 datapoints, then degrees of freedom of the model is 8 (10 minus the number of parameters).\n",
    "\n",
    "The null hypotheses of the F-test states that the model is indistinguishable from the reduced model, which means that the features contribute nothing to the explanation of the target variable. Instead of reading the F statistic, it's easier to read the associated p-value of it. The lower the p-value, the better for our model. Namely, if the p-value of the F-test for our model is less than or equal to 0.1 (or even less than or equal to 0.05), we say that our model is useful and contributes something that is statistically significant in the explanation of the target.\n",
    "\n",
    "Let's see the F statistic of our medical costs model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>25.740</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>3756.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>female</td>\n",
       "      <td>33.440</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>8240.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>female</td>\n",
       "      <td>27.740</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>7281.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>29.830</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>6406.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>25.840</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>28923.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    bmi  children smoker     region   charges\n",
       "0   19  female 27.900         0    yes  southwest 16884.900\n",
       "1   18    male 33.770         1     no  southeast  1725.550\n",
       "2   28    male 33.000         3     no  southeast  4449.460\n",
       "3   33    male 22.705         0     no  northwest 21984.500\n",
       "4   32    male 28.880         0     no  northwest  3866.860\n",
       "5   31  female 25.740         0     no  southeast  3756.620\n",
       "6   46  female 33.440         1     no  southeast  8240.590\n",
       "7   37  female 27.740         3     no  northwest  7281.510\n",
       "8   37    male 29.830         2     no  northeast  6406.410\n",
       "9   60  female 25.840         0     no  northwest 28923.100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'medicalcosts'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "insurance_df = pd.read_sql_query('select * from medicalcosts',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()\n",
    "\n",
    "insurance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.747\n",
      "Model:                            OLS   Adj. R-squared:                  0.747\n",
      "Method:                 Least Squares   F-statistic:                     986.5\n",
      "Date:                Mon, 26 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        16:23:23   Log-Likelihood:                -13557.\n",
      "No. Observations:                1338   AIC:                         2.712e+04\n",
      "Df Residuals:                    1333   BIC:                         2.715e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.163e+04    947.267    -12.281      0.000   -1.35e+04   -9775.195\n",
      "is_male     -109.0414    334.665     -0.326      0.745    -765.568     547.486\n",
      "is_smoker   2.383e+04    414.187     57.544      0.000     2.3e+04    2.46e+04\n",
      "age          259.4531     11.942     21.727      0.000     236.027     282.880\n",
      "bmi          323.0510     27.529     11.735      0.000     269.046     377.056\n",
      "==============================================================================\n",
      "Omnibus:                      299.394   Durbin-Watson:                   2.076\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              708.640\n",
      "Skew:                           1.212   Prob(JB):                    1.32e-154\n",
      "Kurtosis:                       5.614   Cond. No.                         292.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "insurance_df[\"is_male\"] = pd.get_dummies(insurance_df.sex, drop_first=True)\n",
    "insurance_df[\"is_smoker\"] = pd.get_dummies(insurance_df.smoker, drop_first=True)\n",
    "\n",
    "# Y is the target variable\n",
    "Y = insurance_df['charges']\n",
    "\n",
    "# X is the feature set\n",
    "X = insurance_df[['is_male','is_smoker', 'age', 'bmi']]\n",
    "\n",
    "# We add constant to the model as it's a best practice\n",
    "# to do so everytime!\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# We fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# We print the summary results.\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model's F statistic is 986.5 and the associated p-value is very close to zero. This means that, our features add some information to the reduced model and our model is useful for explaning the charges.\n",
    "\n",
    "However, F-test doesn't quantify how much information our model contributes. This requires R-squared, which we discuss next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying the performance of a model in the training set\n",
    "\n",
    "R-squared is probably the most common measure of goodness of fit in a linear regression model. It is a proportion (between 0 and 1) that expresses how much variance in the outcome variable is explained by the explanatory variables in the model. Generally speaking, higher $R^2$ values are better to a point — a low $R^2$ indicates that our model isn't explaining much information about the outcome, which means it will not give very good predictions. However, a very high $R^2$ is a warning sign of overfitting. No dataset is a perfect representation of reality, so a model that perfectly fits our data ($R^2$ of 1 or close to 1) is likely to be biased by quirks in the data, and will perform less well on the test set.\n",
    "\n",
    "In the regression summary table above, we see that the R-squared value of our medical costs model is 0.747. This means that our model explains 74.7% of the variance in the charges, leaving 25.3% unexplained. We can conclude that there's still room for improvement. Let's fit the model in the previous checkpoint again where we included the interaction of body mass index (bmi) and is_smoking dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.837\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     1365.\n",
      "Date:                Fri, 02 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        10:36:36   Log-Likelihood:                -13265.\n",
      "No. Observations:                1338   AIC:                         2.654e+04\n",
      "Df Residuals:                    1332   BIC:                         2.657e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const         -2071.0750    840.644     -2.464      0.014   -3720.206    -421.944\n",
      "is_male        -473.4954    269.612     -1.756      0.079   -1002.406      55.415\n",
      "is_smoker     -2.019e+04   1666.492    -12.117      0.000   -2.35e+04   -1.69e+04\n",
      "age             266.3723      9.612     27.713      0.000     247.516     285.228\n",
      "bmi               7.9686     25.044      0.318      0.750     -41.160      57.098\n",
      "bmi_is_smoker  1435.6081     53.242     26.964      0.000    1331.160    1540.056\n",
      "==============================================================================\n",
      "Omnibus:                      710.004   Durbin-Watson:                   2.059\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4260.532\n",
      "Skew:                           2.491   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.183   Cond. No.                         661.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = insurance_df['charges']\n",
    "\n",
    "# This is the interaction between bmi and smoking\n",
    "insurance_df[\"bmi_is_smoker\"] = insurance_df.bmi * insurance_df.is_smoker\n",
    "\n",
    "# X is the feature set\n",
    "X = insurance_df[['is_male','is_smoker', 'age', 'bmi', \"bmi_is_smoker\"]]\n",
    "\n",
    "# We add constant to the model as it's a best practice\n",
    "# to do so everytime!\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# We fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# We print the summary results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared of this model is 0.837 which is higher than our previous model's. This improvement indicates that the interaction of bmi and is_smoker explains some previously unexplained variance in the charges. \n",
    "\n",
    "As we said before, high R-squared values are generally desirable. However, in some cases, very high R-squared values indicate some potential problems with our model. Specifically:\n",
    "\n",
    "* Very high R-squared value may be a sign of overfitting. If our model is too complex for the data, then it may overfit the training set and do a poor job on the test set. That said, there's not an agreed upon threshold for R-squared to detect overfitting. Instead, it requires a comparison between performance on test and training data. **If our model performs significantly worse on the test set compared to the training set, then we should suspect overfitting**. We'll discuss how to evaluate linear regression models in the test set in the next checkpoint.\n",
    "\n",
    "* R-squared is an inherently biased estimate of the performance in the sense that the more explanatory variables are added to the model, the higher R-squared values we get. This is so even we include irrelevant variables like noises or random data. To mitigate this problem, we usually use a metric called **adjusted R-squared** instead of R-squared. Adjusted R-squared does the same job as R-squared, but it is adjusted according to the number of features included in the model. Hence, **it's always safer to look at the adjusted R-squared value instead of R-squared value**.\n",
    "\n",
    "**A note on negative R-squared values**: It is possible get negative R-squared values for some models. In general terms, if a model is weaker than a straight horizontal line, then R-squared value becomes negative. This usually happens when a constant is not included in the model. Getting a negative value for R-squared means that your model does very poorly in explaning the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different models\n",
    "\n",
    "Comparing different models and chosing the best one is one of the essential practices in data science. Often, we try several models and evaluate their performance on a test set in order to determine the top performing one. However, *inference* is also a critical task when it comes to linear regression models. Unlike testing the predictive power, in inference, we care about the explanatory power of our models.\n",
    "\n",
    "Throughout this checkpoint, we saw that we can measure the performance of our models on the training set using F-test or R-squared. Hence, both F-test and R-squared can be used in the comparison of different models. Unfortunately, the two metrics suffer from some drawbacks that make them inappropriate to use in certain situations.\n",
    "\n",
    "Here we briefly outline how we can use F-test and R-squared in model comparison. Then, we introduce information criterias that we can also use to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using F-test for model comparison\n",
    "\n",
    "We can use an F-test to compare two models if one of them is nested within the other. That is, if the feature set in a model is a subset of the feature set of the other, then we can use F-test. In this case, we say that the model with higher F statistic is superior to the other one.\n",
    "\n",
    "However, if models are not nested, then using F-test may be misleading. It's quite sensitive to the normality of the error terms. If errors are not normally distributed, we should try other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using R-squared for model comparision\n",
    "\n",
    "R-squared can also be used. We already saw that R-squared is biased as it tends to increase with the number of explanatory variables. So, instead of R-squared we can use adjusted R-squared. The higher adjusted R-squared, the better model explains the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using information criteria\n",
    "\n",
    "Using information criteria is also a common way of comparing different models and selecting the best one. Here, we talk about two information criterias known as the **Akaike Information Criterion (AIC)** and **Bayesian Information Criterion (BIC)**. Both take into consideration the sum of the squared errors (SSE), the sample size and the number of parameters.\n",
    "\n",
    "The formula for AIC is:\n",
    "\n",
    "$$nln(SSE)−nln(n)+2p$$ \n",
    "\n",
    "\n",
    "and the formula for BIC is:\n",
    "\n",
    "$$nln(SSE)−nln(n)+pln(n)$$\n",
    "\n",
    "In both of these formulas, $n$ represents the sample size and $p$ represents the number of regression coefficients in the model (including the constant). $ln$ stands for the natural logarithm.\n",
    "\n",
    "For both AIC and BIC, the lower value the better. Hence, we choose the model with the lowest AIC or BIC value. Although we can use any one of the two criterias, AIC is usually criticized for its tendency to overfit. In contrast, BIC penalizes the number of parameters more severely than AIC and hence favors more parsimonious models (that is, models with fewer parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which medical costs model is better?\n",
    "\n",
    "statmodels' `summary()` function gives us all of the above metrics. In the tables above, we see that for our first model, R-squared is 0.747, adjusted R-squared is 0.747, F statistic is 986.5, AIC is 27.120 and BIC is 27.150 whereas for our second model, R-squared is 0.837, adjusted R-squared is 0.836, F statistic is 1365, AIC is 26.540 and BIC is 26.570. According to all of the metrics, our second model seems better than the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "As in previous checkpoints, please submit a link to a single gist that contains links to two Juypyter notebooks (one for each assignment below).\n",
    "\n",
    "### 1. Weather model\n",
    "\n",
    "For this assignment, you'll revisit the historical temperature dataset. To complete this assignment, submit a link in the gist file to the Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* First, load the dataset from the **weatherinszeged** table from Thinkful's database.\n",
    "* Like in the previous checkpoint, build a linear regression model where your target variable is the difference between the *apparenttemperature* and the *temperature*. As explanatory variables, use *humidity* and *windspeed*. Now, estimate your model using OLS. What are the R-squared and adjusted R-squared values? Do you think they are satisfactory? Why? \n",
    "* Next, include the interaction of *humidity* and *windspeed* to the model above and estimate the model using OLS. Now, what is the R-squared of this model? Does this model improve upon the previous one? \n",
    "* Add *visibility* as additional explanatory variable to the first model and estimate it. Did R-squared increase? What about adjusted R-squared? Compare the differences put on the table by the interaction term and the *visibility* in terms of the improvement in the adjusted R-squared. Which one is more useful?\n",
    "* Choose the best one from the three models above with respect to their AIC and BIC scores. Validate your choice by discussing your justification with your mentor.\n",
    "\n",
    "\n",
    "###  2. House prices model\n",
    "\n",
    "In this exercise, you'll work on your house prices model. To complete this assignment, submit a link in the gist file to the Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Run your house prices model again and assess the goodness of fit of your model using F-test, R-squared, adjusted R-squared, AIC and BIC.\n",
    "* Do you think your model is satisfactory? If so, why?\n",
    "* In order to improve the goodness of fit of your model, try different model specifications by adding or removing some variables. \n",
    "* For each model you try, get the goodness of fit metrics and compare your models with each other. Which model is the best and why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
